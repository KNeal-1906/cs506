{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 19\n",
    "\n",
    "Name:  Kenise Neal\n",
    "UID: U55010739\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Linear Model Evaluation\n",
    "\n",
    "## Linear Model Evaluation\n",
    "\n",
    "Notice that R^2 only increases with the number of explanatory variables used. Hence the need for an adjusted R^2 that penalizes for insignificant explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9946341689843935\n",
      "0.9946344854176065\n",
      "0.994656831753138\n",
      "0.9947991472706027\n",
      "0.9948227865342272\n",
      "0.9948540493462387\n",
      "0.9949209886360152\n",
      "0.9949554521711449\n",
      "0.9949708970373282\n",
      "0.9949865262217737\n",
      "0.9949920163118419\n",
      "0.9949935926644607\n",
      "0.9950704619787072\n",
      "0.9950553068026537\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "SAMPLE_SIZE = 100\n",
    "beta = [1, 5]\n",
    "X = -10.0 + 10.0 * np.random.random(SAMPLE_SIZE)\n",
    "Y = beta[0] + beta[1] * X + np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "for i in range(1, 15):\n",
    "    X_transform = PolynomialFeatures(degree=i, include_bias=False).fit_transform(X.reshape(-1, 1))\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_transform, Y)\n",
    "    print(model.score(X_transform, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Hypothesis Testing Sandbox (follow along in class) [Notes](https://medium.com/@gallettilance/hypothesis-testing-almost-everything-you-need-to-know-ce812ded50b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3125\n",
      "[1, 1, 1, 1, 1]\n",
      "0.03125\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AxesSubplot' object has no attribute 'bar_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-abd7fcc3479c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigitize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AxesSubplot' object has no attribute 'bar_label'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "flips = [1, 0, 0, 1, 0]\n",
    "\n",
    "def num_successes(flips):\n",
    "    return sum(flips)\n",
    "\n",
    "print(binom.pmf(num_successes(flips), len(flips), 1/2))\n",
    "\n",
    "SAMPLE_SIZE = 5\n",
    "flips = [np.random.choice([0, 1]) for _ in range(SAMPLE_SIZE)]\n",
    "print(flips)\n",
    "print(binom.pmf(num_successes(flips), SAMPLE_SIZE, 1/2))\n",
    "\n",
    "p_est = []\n",
    "\n",
    "for _ in range(1000):\n",
    "    flips = [np.random.choice([0, 1]) for _ in range(SAMPLE_SIZE)]\n",
    "    p_est.append(sum(flips) / SAMPLE_SIZE)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "_, bins, patches = ax.hist(p_est, bins=SAMPLE_SIZE + 1)\n",
    "p = np.digitize([2/5], bins)\n",
    "patches[p[0]-1].set_facecolor('r')\n",
    "ax.bar_label(patches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Plot a data set and fitted line through the point when there is no relationship between X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SAMPLE_SIZE = 10\n",
    "\n",
    "xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "y = 0+ 0*xlin+ np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "intercept = np.ones(np.shape(xlin)[0])\n",
    "X = np.array([intercept, xlin]).T\n",
    "beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "xplot = np.linspace(-1,1,20)\n",
    "yestplot = beta[0] + beta[1] * xplot\n",
    "plt.plot(xplot, yestplot,'b-',lw=2)\n",
    "plt.plot(xlin, y,'ro',markersize=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Using the above code, plot a histogram of the parameter estimates for the slope after generating `1000` independent datasets. Comment on what the plot means. Increase the sample size to see what happens to the plot. Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "    y = 0+ 0*xlin+ np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "    intercept = np.ones(np.shape(xlin)[0])\n",
    "    X = np.array([intercept, xlin]).T\n",
    "    beta_est = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    beta_hist.append(beta_est[1])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) We know that:\n",
    "\n",
    "$$\\hat\\beta-\\beta \\sim \\mathcal{N}(0,\\sigma^2 (X^TX)^{-1})$$\n",
    "\n",
    "thus for each component $k$ of $\\hat\\beta$ (here there are only two - one slope and one intercept)\n",
    "\n",
    "$$\\hat\\beta_k -\\beta_k \\sim \\mathcal{N}(0, \\sigma^2 S_{kk})$$\n",
    "\n",
    "where $S_{kk}$ is the $k^\\text{th}$ diagonal element of $(X^TX)^{-1}$. Thus, we know that \n",
    "\n",
    "$$z_k = \\frac{\\hat\\beta_k -\\beta_k}{\\sqrt{\\sigma^2 S_{kk}}} \\sim \\mathcal{N}(0,1)$$\n",
    "\n",
    "Verify that this is the case through a simulation and compare it to the standard normal pdf by plotting it on top of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "    y = 0+ 0*xlin+ np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "    intercept = np.ones(np.shape(xlin)[0])\n",
    "    X = np.array([intercept, xlin]).T\n",
    "    beta_est = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    beta_hist.append(beta_est[1])\n",
    "\n",
    "xs = np.linspace(-10,10,1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "ax.plot(xs, norm.pdf(xs), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Above we normalized $\\hat\\beta$ by subtracting the mean and dividing by the standard deviation. While we know that the estimate of beta is an unbiased estimator, we don't know the standard deviation. So in practice when doing a hypothesis test where we want to assume that $\\beta = 0$, we can simply use $\\hat\\beta$ in the numerator. However we don't know the standard deviation and need to use an unbiased estimate of the standard deviation instead. This estimate is the standard error `s`\n",
    "\n",
    "$$s = \\sqrt{\\frac{RSS}{n - p}}$$\n",
    "\n",
    "where p is the number of parameters beta (here there are 2 - one slope and one intercept). This normalized $\\hat\\beta$ can be shown to follow a t-distribution with `n-p` degrees of freedom. Verify this is the case with a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "def standard_error(ytrue, ypred):\n",
    "    return np.sqrt(np.sum((ytrue - ypred)**2) / (len(ytrue) - 2))\n",
    "\n",
    "beta_hist = []\n",
    "for _ in range(1000):\n",
    "    xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "    y = 0+ 0*xlin+ np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "    intercept = np.ones(np.shape(xlin)[0])\n",
    "    X = np.array([intercept, xlin]).T\n",
    "    beta_est = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    beta_hist.append(beta_est[1] / standard_error(y, X @ beta_est))\n",
    "\n",
    "xs = np.linspace(-10,10,1000)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "ax.plot(xs, t.pdf(xs, SAMPLE_SIZE - 2), color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) You are given the following dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([-0.1920605, -0.11290798, -0.56434374, -0.67052057, -0.19233284, -0.42403586, -0.8114285, -0.38986946, -0.37384161, -0.50930229])\n",
    "y = np.array([-0.34063108, -0.33409286, 0.34245857, 0.11062295, 0.76682389, 0.86592388, -1.68912015, -2.01463592, 1.61798563, 0.60557414])\n",
    "\n",
    "intercept = np.ones(np.shape(x)[0])\n",
    "X = np.array([intercept, x]).T\n",
    "beta_hat = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "print(beta_hat)\n",
    "\n",
    "xplot = np.linspace(-1,.25,20)\n",
    "yestplot = beta_hat[0] + beta_hat[1] * xplot\n",
    "plt.plot(xplot, yestplot,'b-',lw=2)\n",
    "plt.plot(x, y,'ro',markersize=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what is the probability of observing a dataset at least as extreme as the above assuming $\\beta = 0$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_hist = []\n",
    "count = 0\n",
    "for _ in range(100000):\n",
    "    xlin = -1.0 + 1.0 * np.random.random(SAMPLE_SIZE)\n",
    "    y = 0+ 0*xlin+ np.random.randn(SAMPLE_SIZE)\n",
    "\n",
    "    intercept = np.ones(np.shape(xlin)[0])\n",
    "    X = np.array([intercept, xlin]).T\n",
    "    beta_est = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    beta_hist.append(beta_est[1])\n",
    "    if beta_est[1] > beta_hat[1]:\n",
    "        count += 1\n",
    "    elif beta_est[1] < -beta_hat[1]:\n",
    "        count += 1\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(beta_hist, bins=100, density=True)\n",
    "plt.show()\n",
    "print(\"The probability of observing a dataset at least as extreme as the above is\", (count / 100000)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
